<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>GSQA: An End-to-End Model for Generative Spoken Question Answering - Ming-Hao Hsu</title>
    <link
      href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400&display=swap"
      rel="stylesheet"
    />
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css"
      rel="stylesheet"
    />
    <link
      href="/static/css/style.css"
      rel="stylesheet"
    />
  </head>
  <body>
    <nav class="navbar navbar-expand-lg navbar-dark">
      <div class="container">
        <a class="navbar-brand" href="/"
          >Ming-Hao Hsu</a
        >
        <button
          class="navbar-toggler"
          type="button"
          data-bs-toggle="collapse"
          data-bs-target="#navbarNav"
          aria-controls="navbarNav"
          aria-expanded="false"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarNav">
          <ul class="navbar-nav me-auto">
            <li class="nav-item">
              <a class="nav-link" href="/about/">About</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="/research/">Research</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="/publications/"
                >Publications</a
              >
            </li>
            <li class="nav-item">
              <a class="nav-link" href="/blog/">Blog</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="/contact/">Contact</a>
            </li>
          </ul>
          <button
            id="dark-mode-toggle"
            class="btn btn-sm btn-outline-secondary"
          >
            <img
              src="/static/images/darkmode_icon.svg"
              alt="Dark Mode"
              class="mode-icon dark-icon"
            />
            <img
              src="/static/images/lightmode_icon.svg"
              alt="Light Mode"
              class="mode-icon light-icon"
            />
          </button>
        </div>
      </div>
    </nav>

    <div class="container mt-4">
<div class="container">
  <h1 class="mb-4 text-center">GSQA: An End-to-End Model for Generative Spoken Question Answering</h1>
  <div class="row justify-content-center">
    <div class="col-md-8 text-center">
      <img
        src="/static/images/gsqa.png"
        alt="Paper structure"
        class="img-fluid mb-4 paper-image"
      />
    </div>
  </div>
  <div class="row justify-content-center">
    <div class="col-md-10">
      <p><strong>Authors:</strong> Min-Han Shih*, Ho-Lam Chung*, Yu-Chi Pai*, Ming-Hao Hsu, Guan-Ting Lin, Shang-Wen Li, Hung-yi Lee</p>
      <p><strong>Journal:</strong> Proceedings of the 2024 Conference of the International Speech Communication Association (INTERSPEECH)</p>
      <p><strong>Year:</strong> 2024</p>
      <h2>Abstract</h2>
      <p class="paper-abstract">In recent advancements in spoken question answering (QA), end-to-end models have made significant strides. However, previous research has primarily focused on extractive span selection. While this extractive-based approach is effective when answers are present directly within the input, it falls short in addressing abstractive questions, where answers are not directly extracted but inferred from the given information. To bridge this gap, we introduce the first end-to-end Generative Spoken Question Answering (GSQA) model that empowers the system to engage in abstractive reasoning. The challenge in training our GSQA model lies in the absence of a spoken abstractive QA dataset. We propose using text models for initialization and leveraging the extractive QA dataset to transfer knowledge from the text generative model to the spoken generative model. Experimental results indicate that our model surpasses the previous extractive model by 3% on extractive QA datasets. Furthermore, the GSQA model has only been fine-tuned on the spoken extractive QA dataset. Despite not having seen any spoken abstractive QA data, it can still closely match the performance of the cascade model. In conclusion, our GSQA model shows the potential to generalize to a broad spectrum of questions, thus further expanding the spoken question answering capabilities of abstractive QA.</p>
    </div>
  </div>
</div>
</div>

    <footer class="footer py-3">
      <div class="container text-center">
        <span>&copy; 2023 Ming-Hao Hsu. All rights reserved.</span>
      </div>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>
    <script src="/static/js/script.js"></script>
    <script src="/static/js/dark-mode.js"></script>
    
  </body>
</html>